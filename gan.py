# -*- coding: utf-8 -*-
"""gan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jiP_mshGOwywaLaZ9td9uHgo1QhpVnpX
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, Reshape, Flatten, LeakyReLU, BatchNormalization
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt

print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

"""Building generator Model"""

def build_generator():
    model = Sequential()
    model.add(Dense(128, input_dim=100))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(256))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(28 * 28 * 1, activation='tanh'))
    model.add(Reshape((28, 28, 1)))
    return model

"""Building Discriminator model

"""

def build_discriminator():
    model = Sequential()
    model.add(Flatten(input_shape=(28, 28, 1)))
    model.add(Dense(256))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(128))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(1, activation='sigmoid'))
    return model

"""
# Compile the discriminator

"""

discriminator = build_discriminator()
discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

"""# Compile the generator

"""

generator = build_generator()
noise = tf.keras.Input(shape=(100,))
img = generator(noise)
discriminator.trainable = False
validity = discriminator(img)

"""# Combine the models to create the GAN

"""

gan = tf.keras.Model(noise, validity)
gan.compile(loss='binary_crossentropy', optimizer='adam')

# Load and preprocess the MNIST dataset
(X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()
X_train = (X_train - 127.5) / 127.5
X_train = np.expand_dims(X_train, axis=3)

"""# Define the training function

"""

def train(epochs, batch_size=128, save_interval=50):
    half_batch = batch_size // 2

    if not os.path.exists('static/generated_images'):
        os.makedirs('static/generated_images')

    for epoch in range(epochs):
        idx = np.random.randint(0, X_train.shape[0], half_batch)
        real_imgs = X_train[idx]

        noise = np.random.normal(0, 1, (half_batch, 100))
        fake_imgs = generator.predict(noise)

        real_labels = np.ones((half_batch, 1))
        fake_labels = np.zeros((half_batch, 1))

        d_loss_real = discriminator.train_on_batch(real_imgs, real_labels)
        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_labels)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        noise = np.random.normal(0, 1, (batch_size, 100))
        valid_labels = np.ones((batch_size, 1))

        g_loss = gan.train_on_batch(noise, valid_labels)

        if epoch % save_interval == 0:
            print(f"Epoch {epoch} - D Loss: {d_loss[0]}, D Acc: {d_loss[1]}, G Loss: {g_loss}")
            save_imgs(epoch)

    generator.save('generator_model.h5')

# Define the function to save generated images
def save_imgs(epoch):
    noise = np.random.normal(0, 1, (16, 100))
    gen_imgs = generator.predict(noise)
    gen_imgs = 0.5 * gen_imgs + 0.5

    fig, axs = plt.subplots(4, 4)
    cnt = 0
    for i in range(4):
        for j in range(4):
            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')
            axs[i, j].axis('off')
            cnt += 1
    fig.savefig(f"static/generated_images/gan_image_epoch_{epoch}.png")
    plt.close()

# Start the training
train(epochs=1000, batch_size=64, save_interval=100)